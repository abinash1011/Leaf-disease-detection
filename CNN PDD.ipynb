{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ad132e-bc6a-4100-a101-350c261e6dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:41:43.841489Z",
     "iopub.status.busy": "2023-09-26T14:41:43.841084Z",
     "iopub.status.idle": "2023-09-26T14:41:49.598719Z",
     "shell.execute_reply": "2023-09-26T14:41:49.598062Z",
     "shell.execute_reply.started": "2023-09-26T14:41:43.841464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 14:41:44.524415: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-26 14:41:44.598670: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-26 14:41:45.111403: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-26 14:41:45.113939: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 14:41:46.626796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import itertools\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e4891-6e07-4d66-93b3-fef5dbc2924b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bed6267-6562-4d59-ac3f-a5549874cb80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T06:19:17.263562Z",
     "iopub.status.busy": "2023-09-27T06:19:17.263165Z",
     "iopub.status.idle": "2023-09-27T06:19:19.119022Z",
     "shell.execute_reply": "2023-09-27T06:19:19.118166Z",
     "shell.execute_reply.started": "2023-09-27T06:19:17.263540Z"
    }
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='my_cnn_model.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89136ec4-1d06-4c92-ba12-803239816cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T06:19:20.584093Z",
     "iopub.status.busy": "2023-09-27T06:19:20.583725Z",
     "iopub.status.idle": "2023-09-27T06:19:20.587694Z",
     "shell.execute_reply": "2023-09-27T06:19:20.586985Z",
     "shell.execute_reply.started": "2023-09-27T06:19:20.584071Z"
    }
   },
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_index = input_details[0]['index'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddb22590-3e21-4cac-b6b3-c88dd015bd23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T06:19:24.540059Z",
     "iopub.status.busy": "2023-09-27T06:19:24.539665Z",
     "iopub.status.idle": "2023-09-27T06:19:24.543354Z",
     "shell.execute_reply": "2023-09-27T06:19:24.542624Z",
     "shell.execute_reply.started": "2023-09-27T06:19:24.540036Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = \"new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Grape___Black_rot/00cff577-afd4-4e36-ac9c-a52aa6ae5949___FAM_B.Rot 0508_flipLR.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05281fa5-4e1e-4003-8635-4ea5774f6652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T06:20:00.707765Z",
     "iopub.status.busy": "2023-09-27T06:20:00.707388Z",
     "iopub.status.idle": "2023-09-27T06:20:00.712405Z",
     "shell.execute_reply": "2023-09-27T06:20:00.711778Z",
     "shell.execute_reply.started": "2023-09-27T06:20:00.707742Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "image = cv2.imread(input_data)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "model_image_size = (256, 256)\n",
    "resized_image = cv2.resize(image, model_image_size, interpolation = cv2.INTER_CUBIC)\n",
    "resized_image = resized_image.astype(np.float32)\n",
    "resized_image /= 255\n",
    "test_image = np.expand_dims(resized_image, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90134c26-4427-4b03-92e5-fc4620a5f8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T06:20:03.518107Z",
     "iopub.status.busy": "2023-09-27T06:20:03.517731Z",
     "iopub.status.idle": "2023-09-27T06:20:03.625081Z",
     "shell.execute_reply": "2023-09-27T06:20:03.624472Z",
     "shell.execute_reply.started": "2023-09-27T06:20:03.518085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the input tensor\n",
    "interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "output_data = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "112cc98c-8b33-47de-a375-25de140aed88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T06:20:05.806869Z",
     "iopub.status.busy": "2023-09-27T06:20:05.806492Z",
     "iopub.status.idle": "2023-09-27T06:20:05.811285Z",
     "shell.execute_reply": "2023-09-27T06:20:05.810708Z",
     "shell.execute_reply.started": "2023-09-27T06:20:05.806844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_conv2d_10_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 256, 256,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 256, 256,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27572123-ba8f-475b-8395-161bb8ee09ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T06:20:08.544916Z",
     "iopub.status.busy": "2023-09-27T06:20:08.544548Z",
     "iopub.status.idle": "2023-09-27T06:20:08.548941Z",
     "shell.execute_reply": "2023-09-27T06:20:08.548350Z",
     "shell.execute_reply.started": "2023-09-27T06:20:08.544893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = output_data.argmax()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1480192-8770-4875-a3c4-d174190e1dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T05:08:00.391816Z",
     "iopub.status.busy": "2023-09-27T05:08:00.391423Z",
     "iopub.status.idle": "2023-09-27T05:08:00.396048Z",
     "shell.execute_reply": "2023-09-27T05:08:00.395489Z",
     "shell.execute_reply.started": "2023-09-27T05:08:00.391789Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def run_tflite_model(tflite_file, test_image):\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    input_index = input_details[0]['index'] \n",
    "\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    prediction = output.argmax()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04cd9c99-d1bd-4f90-938d-886f1f023cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T05:19:41.995966Z",
     "iopub.status.busy": "2023-09-27T05:19:41.995563Z",
     "iopub.status.idle": "2023-09-27T05:19:41.998995Z",
     "shell.execute_reply": "2023-09-27T05:19:41.998460Z",
     "shell.execute_reply.started": "2023-09-27T05:19:41.995942Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63e7c71d-b9cc-4774-bef5-e5f44c7c8fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T05:26:13.688058Z",
     "iopub.status.busy": "2023-09-27T05:26:13.687659Z",
     "iopub.status.idle": "2023-09-27T05:26:13.731269Z",
     "shell.execute_reply": "2023-09-27T05:26:13.730363Z",
     "shell.execute_reply.started": "2023-09-27T05:26:13.688033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_input:0', 'index': 0, 'shape': array([  1, 100, 100,   3], dtype=int32), 'shape_signature': array([ -1, 100, 100,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 5 but expected 4 for input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# resized_image = cv2.resize(image, (100, 100), interpolation = cv2.INTER_CUBIC)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tflite_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "Cell \u001b[0;32mIn[34], line 12\u001b[0m, in \u001b[0;36mrun_tflite_model\u001b[0;34m(tflite_file, test_image)\u001b[0m\n\u001b[1;32m      9\u001b[0m input_details \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_input_details()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m output_details \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_output_details()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[1;32m     14\u001b[0m output \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_tensor(output_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/other_od/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:720\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    705\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 5 but expected 4 for input 0."
     ]
    }
   ],
   "source": [
    "converted_model = 'plant_disease/AllPlantDiseaseCNN.tflite'\n",
    "input_data = \"new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655_180deg.JPG\"\n",
    "\n",
    "img = cv2.imread(input_data)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "resized = cv2.resize(image, (100, 100)).astype('float32')\n",
    "resized_image = cv2.resize(image, (100, 100), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "prediction = run_tflite_model(converted_model, test_image)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705591d6-0357-4041-90e6-00f41cd63ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d4e6a-2f2b-425a-9687-71f394e3c5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1571aaf-fbe8-45d2-a50e-360ca0ace0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35a4dd-b398-41d9-98e7-93bbbc089c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aaf2dd-045f-498f-bd56-669da7fbcfed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "other_od",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
